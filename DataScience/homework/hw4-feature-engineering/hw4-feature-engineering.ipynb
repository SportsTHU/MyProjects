{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Basic knowledge of feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## Question 1: A good feature should be discriminative and representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## Question 2: Why is image feature extraction hard? \n",
    "\n",
    "# Ans: Individual pixel color values are NOT an adequate feature to determine correspondences\n",
    "#     Because pixels are not characteristic of an image (for example, a dog's image can have red pixels, \n",
    "#     while a horse's can also have red pixels)\n",
    "#     So we need to consider 'blocks of pixels', for example, taking the\n",
    "#     surroounding pixels into consideration.\n",
    "#     Only in  this way, can we reduce the effect of rotation, flipping, \n",
    "#     deformation, and ect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## Question 3: As we have learned in class, both 'Maximum entropy' and 'Smallest margin' can be used to\n",
    "##             measure uncertainty in active learning. Please explain which one is better for active learning and why?\n",
    "##             Note that: this is an open question and you can answer in Chinese as well.\n",
    "\n",
    "## My answer:\n",
    "\n",
    "# In my opinion, the 'Maximum ewntropy' is better.\n",
    "# We can approach this problem from 2 aspects:\n",
    "#     on the one hand, 'maximun entropy' is more comprehensive, it take the data of all samples into consideration\n",
    "#     on the other hand, active learning is improve model's performance with lables as few as possible \n",
    "#     So sonsidering these 2 factors, I think maximum entropy is better because it can reflect the data set comprehensively, and this can better\n",
    "#     select the ambiguous instances, then presenting them for extra labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## Given a corpus as:\n",
    "corpus = ['The goal of this lecture is to explain text processing.',\n",
    "          'The bag of words model is one such approach.',\n",
    "          'Text processing via bag of words.',\n",
    "          'Data science includes text processing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 15)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 16)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 17)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 11)\t1\n",
      "  (1, 15)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 19)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 10)\t1\n",
      "  (1, 13)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 14)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 19)\t1\n",
      "  (2, 18)\t1\n",
      "  (3, 14)\t1\n",
      "  (3, 11)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 12)\t1\n",
      "  (3, 5)\t1\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install sklearn\n",
    "## Question 4: Use BOW to extract features of the given corpus. \n",
    "## \n",
    "## Your code here\n",
    "## \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 11)\t0.23360869991447142\n",
      "  (0, 14)\t0.23360869991447142\n",
      "  (0, 3)\t0.3659931706709981\n",
      "  (0, 17)\t0.3659931706709981\n",
      "  (0, 6)\t0.2885532196006135\n",
      "  (0, 7)\t0.3659931706709981\n",
      "  (0, 16)\t0.3659931706709981\n",
      "  (0, 9)\t0.23360869991447142\n",
      "  (0, 4)\t0.3659931706709981\n",
      "  (0, 15)\t0.2885532196006135\n",
      "  (1, 0)\t0.38086516913285073\n",
      "  (1, 13)\t0.38086516913285073\n",
      "  (1, 10)\t0.38086516913285073\n",
      "  (1, 8)\t0.38086516913285073\n",
      "  (1, 19)\t0.30027847400958324\n",
      "  (1, 1)\t0.30027847400958324\n",
      "  (1, 6)\t0.30027847400958324\n",
      "  (1, 9)\t0.24310130388692774\n",
      "  (1, 15)\t0.30027847400958324\n",
      "  (2, 18)\t0.5371830325370646\n",
      "  (2, 19)\t0.4235212730041086\n",
      "  (2, 1)\t0.4235212730041086\n",
      "  (2, 11)\t0.3428769712206024\n",
      "  (2, 14)\t0.3428769712206024\n",
      "  (2, 9)\t0.3428769712206024\n",
      "  (3, 5)\t0.5119917161748856\n",
      "  (3, 12)\t0.5119917161748856\n",
      "  (3, 2)\t0.5119917161748856\n",
      "  (3, 11)\t0.3267976803045626\n",
      "  (3, 14)\t0.3267976803045626\n"
     ]
    }
   ],
   "source": [
    "## Question 5: Use TFIDF to extract features of the given corpus. \n",
    "## \n",
    "## Your code here\n",
    "## \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "Y = vectorizer.fit_transform(corpus)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04576098,  0.04882504,  0.00825521, -0.00122285, -0.00679342,\n",
       "         0.00365627,  0.00475215, -0.03505001, -0.004961  ,  0.01315367]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Question 6: Use Word2Vec to extract features of the given corpus. \n",
    "# !pip3 install gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.sklearn_api import W2VTransformer\n",
    "# Create a model to represent each word by a 10 dimensional vector\n",
    "model = W2VTransformer(size=10, min_count=1, seed=1)\n",
    "## The model trained on the common_texts\n",
    "# What is the vector representation of the word ‘graph’? \n",
    "common_texts\n",
    "wordvecs = model.fit(common_texts).transform(['graph']) \n",
    "wordvecs\n",
    "## \n",
    "## You should extract the vector representation of the word 'text' by the model trained on the given corpus.\n",
    "## Note that: the formulation of the given corpus is different from that of common_texts, \n",
    "## you should transform the given corpus to the the formulation of common_texts first.\n",
    "## \n",
    "## Your code here\n",
    "## In next cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0494656   0.03413517  0.00032518 -0.00489395 -0.02507001 -0.00917046\n",
      "  -0.03160857  0.03087081  0.01838998  0.02286113]]\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "## Your code here\n",
    "## \n",
    "words_list = []\n",
    "for sentence in corpus:\n",
    "    words_list.append(sentence.split())\n",
    "# print(words_list)\n",
    "model = W2VTransformer(size=10, min_count=1, seed=1)\n",
    "wordvecs_common_text = model.fit(words_list).transform(['text']) \n",
    "print(wordvecs_common_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time series feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## Question 7: Use decompose (model='additive') to extract time series features of the given time series\n",
    "from random import randrange\n",
    "import math\n",
    "from pandas import Series\n",
    "series = Series([20*math.sin(i/18*math.pi) + i + randrange(10) for i in range(1,360)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "## \n",
    "## Your code here\n",
    "## \n",
    "# ?seasonal_decompose\n",
    "# print(series)\n",
    "result = seasonal_decompose(series, model='multiplicative', freq=36)\n",
    "result.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Question 8: Use Discrete Fourier Transform (DFT) to extract time series features of the given time series\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "series = Series([np.cos(2*math.pi*1/8*n+math.pi/8) for n in range(800)])\n",
    "## \n",
    "## Your code here\n",
    "## \n",
    "sp = np.fft.fft(series)\n",
    "freq = np.fft.fftfreq(series.shape[-1])\n",
    "plt.plot(freq, sp.real, freq, sp.imag)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the image:  (485, 729)\n",
      "The shape of feature description:  (418, 128)\n"
     ]
    }
   ],
   "source": [
    "## Use SIFT in opencv-python to extract image features on the given image 'morning.jpg'\n",
    "# !pip install opencv-python==3.4.2.16\n",
    "# !pip install opencv-contrib-python==3.4.2.16\n",
    "## Note that: NOT all versions of opencv-contrib-python includes SIFT in cv2.xfeatures2d, \n",
    "## but this specified version does\n",
    "import cv2\n",
    "import numpy as np\n",
    "name = 'dog.jpg'\n",
    "img = cv2.imread(name)\n",
    "gray_img= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "print(\"The shape of the image: \", gray_img.shape)\n",
    "siftDetector= cv2.xfeatures2d.SIFT_create()\n",
    "## Note that: SIFT was re-organized in opencv thus you should import it like this.\n",
    "\n",
    "## finds the keypoint in the images\n",
    "kp = siftDetector.detect(gray_img,None)\n",
    "## draws the small circles on the locations of keypoints\n",
    "cv2.drawKeypoints(gray_img,kp,img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('sift_keypoint_example' + name, img) ## Save Example\n",
    "## directly find keypoints and descriptors in a single step \n",
    "kp, des = siftDetector.detectAndCompute(gray_img,None)\n",
    "print(\"The shape of feature description: \", des.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescaling Done!\n"
     ]
    }
   ],
   "source": [
    "## Question 9: Please rescale the given image 'dog.jpg' at a random ratio between 0.3 with 1.5.\n",
    "##          Note that: the width and height of the given image should be rescaled at a different ratio.\n",
    "##          Repeat this operation five times, then you will get five new images with different scale.\n",
    "##\n",
    "##          Please extract the SIFT features of these images respectively and use 'imwrite' to save them.\n",
    "##          An example of saving keypoints on the input image is shown as follow:\n",
    "##          cv2.drawKeypoints(gray_img,kp,img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "##          cv2.imwrite('sift_keypoint_' + name, img)\n",
    "##\n",
    "## \n",
    "## Your code here\n",
    "## \n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "name = 'dog.jpg'\n",
    "\n",
    "def rescale():\n",
    "    for i in range(6):\n",
    "        img = cv2.imread(name)\n",
    "        rescaled_img = cv2.resize(img, (0,0), fx=random.uniform(0.3, 1.5), fy=random.uniform(0.3, 1.5))\n",
    "        gray = cv2.cvtColor(rescaled_img,cv2.COLOR_BGR2GRAY)\n",
    "        siftDetector= cv2.xfeatures2d.SIFT_create()\n",
    "        kp = siftDetector.detect(gray, None)\n",
    "        cv2.drawKeypoints(gray, kp, rescaled_img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        cv2.imwrite(str(i) + name, rescaled_img) ## Save Example\n",
    "#         kp, des = siftDetector.detectAndCompute(gray,None)\n",
    "#         print(\"The shape of feature description: \", des.shape)\n",
    "    return\n",
    "\n",
    "rescale()\n",
    "print(\"Rescaling Done!\")\n",
    "\n",
    "\n",
    "#         feat_img = rescaled_img\n",
    "#         siftDetector= cv2.xfeatures2d.SIFT_create()\n",
    "#         kp = siftDetector.detect(rescaled_img, None)\n",
    "#         cv2.drawKeypoints(rescaled_img, kp, feat_img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "#         cv2.imwrite('feat_rescaled' + str(i) + name, feat_img)\n",
    "\n",
    "# siftDetector= cv2.xfeatures2d.SIFT_create()\n",
    "# ## Note that: SIFT was re-organized in opencv thus you should import it like this.\n",
    "\n",
    "# ## finds the keypoint in the images\n",
    "# kp = siftDetector.detect(rotated_dog,None)\n",
    "# ## draws the small circles on the locations of keypoints\n",
    "# cv2.drawKeypoints(rotated_dog,kp,img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "# cv2.imwrite('rotated_feature' + name, img) ## Save Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## Question 10: Please rotate the given image 'dog.jpg' 30, 60, 90, 120, 150, 180 degrees clockwise,\n",
    "##              then you will get six new images with different rotation angle.\n",
    "##              Please extract the SIFT features of these images respectively and use 'imwrite' to save them.\n",
    "##              An example of saving keypoints on the input image is shown as follow:\n",
    "##              cv2.drawKeypoints(gray_img,kp,img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "##              cv2.imwrite('sift_keypoint_' + name, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# cv2.warpAffine(image, M, (w, h))\n",
    "# # \n",
    "\n",
    "# siftDetector= cv2.xfeatures2d.SIFT_create()\n",
    "# ## Note that: SIFT was re-organized in opencv thus you should import it like this.\n",
    "\n",
    "# ## finds the keypoint in the images\n",
    "# kp = siftDetector.detect(rotated_dog,None)\n",
    "# ## draws the small circles on the locations of keypoints\n",
    "# cv2.drawKeypoints(rotated_dog,kp,img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "# cv2.imwrite('rotated_feature' + name, img) ## Save Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescaling Done!\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "name = 'dog.jpg'\n",
    "def rotate(image, angle, center=None, scale=1.0):\n",
    "    # Get the size\n",
    "    (h, w) = image.shape[:2]\n",
    "    # set the rotation center at the center of the image\n",
    "    if center is None:\n",
    "        center = (w / 2, h / 2)\n",
    "    # carry out \n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    " \n",
    "    # return the rotated fig\n",
    "    return rotated\n",
    "\n",
    "degrees = [30, 60, 90, 120, 150, 180]\n",
    "def rescale():\n",
    "    for deg in degrees:\n",
    "        img = cv2.imread(name)\n",
    "        rescaled_img = rotate(img, deg)\n",
    "        gray = cv2.cvtColor(rescaled_img,cv2.COLOR_BGR2GRAY)\n",
    "        siftDetector= cv2.xfeatures2d.SIFT_create()\n",
    "        kp = siftDetector.detect(gray, None)\n",
    "        cv2.drawKeypoints(gray, kp, rescaled_img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        cv2.imwrite(str(deg) + \"rot\" + name, rescaled_img) ## Save Example\n",
    "        kp, des = siftDetector.detectAndCompute(img,None)\n",
    "    return\n",
    "\n",
    "rescale()\n",
    "print(\"Rescaling Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
